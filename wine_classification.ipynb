{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ1_tvew7ExK",
        "outputId": "d54e89ad-46c2-4316-8fc6-60e27f849860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== WINE CLASSIFICATION PROJECT ===\n",
            "\n",
            "‚úÖ Dataset loaded successfully!\n",
            "Dataset Shape: (178, 13)\n",
            "Features: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
            "Target Classes: ['class_0' 'class_1' 'class_2']\n",
            "Problem: Classify wine cultivar (3 classes)\n",
            "Dataset Shape: (178, 14)\n",
            "Features: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
            "Target: Wine cultivar classification\n",
            "\n",
            "=== EXPLORATORY DATA ANALYSIS ===\n",
            "Missing values:\n",
            "alcohol                         0\n",
            "malic_acid                      0\n",
            "ash                             0\n",
            "alcalinity_of_ash               0\n",
            "magnesium                       0\n",
            "total_phenols                   0\n",
            "flavanoids                      0\n",
            "nonflavanoid_phenols            0\n",
            "proanthocyanins                 0\n",
            "color_intensity                 0\n",
            "hue                             0\n",
            "od280/od315_of_diluted_wines    0\n",
            "proline                         0\n",
            "dtype: int64\n",
            "\n",
            "Target distribution:\n",
            "0    59\n",
            "1    71\n",
            "2    48\n",
            "Name: count, dtype: int64\n",
            "Class names: ['class_0' 'class_1' 'class_2']\n",
            "Dataset info:\n",
            "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
            "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
            "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
            "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
            "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
            "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
            "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
            "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
            "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
            "\n",
            "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
            "count     178.000000  178.000000            178.000000       178.000000   \n",
            "mean        2.295112    2.029270              0.361854         1.590899   \n",
            "std         0.625851    0.998859              0.124453         0.572359   \n",
            "min         0.980000    0.340000              0.130000         0.410000   \n",
            "25%         1.742500    1.205000              0.270000         1.250000   \n",
            "50%         2.355000    2.135000              0.340000         1.555000   \n",
            "75%         2.800000    2.875000              0.437500         1.950000   \n",
            "max         3.880000    5.080000              0.660000         3.580000   \n",
            "\n",
            "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
            "count       178.000000  178.000000                    178.000000   178.000000  \n",
            "mean          5.058090    0.957449                      2.611685   746.893258  \n",
            "std           2.318286    0.228572                      0.709990   314.907474  \n",
            "min           1.280000    0.480000                      1.270000   278.000000  \n",
            "25%           3.220000    0.782500                      1.937500   500.500000  \n",
            "50%           4.690000    0.965000                      2.780000   673.500000  \n",
            "75%           6.200000    1.120000                      3.170000   985.000000  \n",
            "max          13.000000    1.710000                      4.000000  1680.000000  \n",
            "\n",
            "=== DATA PREPROCESSING ===\n",
            "Features shape: (178, 13)\n",
            "Target shape: (178,)\n",
            "Wine classes: [np.int64(0), np.int64(1), np.int64(2)] - ['class_0' 'class_1' 'class_2']\n",
            "Training set: (142, 13)\n",
            "Test set: (36, 13)\n",
            "‚úÖ Features scaled using StandardScaler\n",
            "\n",
            "=== SVC IMPLEMENTATION ===\n",
            "SVC Basic Accuracy: 0.9722\n",
            "\n",
            "üîß Tuning SVC hyperparameters...\n",
            "SVC Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "SVC Best Accuracy: 0.9722\n",
            "\n",
            "=== KNN IMPLEMENTATION ===\n",
            "Best K value: 18\n",
            "KNN Best Accuracy: 0.9722\n",
            "\n",
            "=== MODEL COMPARISON ===\n",
            "Model Performance:\n",
            "SVC Basic: 0.9722\n",
            "SVC Tuned: 0.9722\n",
            "KNN: 0.9722\n",
            "\n",
            "üèÜ Best Model: SVC Basic with 0.9722 accuracy\n",
            "\n",
            "=== DETAILED EVALUATION FOR SVC Basic ===\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       0.93      1.00      0.97        14\n",
            "           2       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.97      0.97        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n",
            "Confusion Matrix:\n",
            "[[12  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  1  9]]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    print(\"üöÄ Running in Google Colab - all packages pre-installed!\")\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    print(\"üíª Running locally\")\n",
        "    IN_COLAB = False\n",
        "    # Uncomment below if packages missing:\n",
        "    # !pip install pandas numpy scikit-learn matplotlib seaborn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# LOAD AND EXPLORE DATA\n",
        "print(\"=== WINE CLASSIFICATION PROJECT ===\\n\")\n",
        "\n",
        "# Loading the sklearn wine dataset (Wine Recognition Dataset)\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine = load_wine()\n",
        "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "y = wine.target  # Wine classes: 0, 1, 2\n",
        "\n",
        "print(\"‚úÖ Dataset loaded successfully!\")\n",
        "print(f\"Dataset Shape: {X.shape}\")\n",
        "print(f\"Features: {list(X.columns)}\")\n",
        "print(f\"Target Classes: {wine.target_names}\")\n",
        "print(f\"Problem: Classify wine cultivar (3 classes)\")\n",
        "\n",
        "# Converting to DataFrame for easier handling\n",
        "df = X.copy()\n",
        "df['target'] = y\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Features: {list(df.columns[:-1])}\")\n",
        "print(f\"Target: Wine cultivar classification\")\n",
        "\n",
        "# EXPLORATORY DATA ANALYSIS\n",
        "print(\"\\n=== EXPLORATORY DATA ANALYSIS ===\")\n",
        "print(f\"Missing values:\\n{X.isnull().sum()}\")\n",
        "print(f\"\\nTarget distribution:\\n{pd.Series(y).value_counts().sort_index()}\")\n",
        "print(f\"Class names: {wine.target_names}\")\n",
        "print(f\"Dataset info:\\n{X.describe()}\")\n",
        "\n",
        "# DATA PREPROCESSING\n",
        "print(\"\\n=== DATA PREPROCESSING ===\")\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Wine classes: {sorted(np.unique(y))} - {wine.target_names}\")\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "# Scaling the features (IMPORTANT for both SVM and KNN)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"‚úÖ Features scaled using StandardScaler\")\n",
        "\n",
        "# IMPLEMENT SVC (SUPPORT VECTOR CLASSIFIER)\n",
        "print(\"\\n=== SVC IMPLEMENTATION ===\")\n",
        "\n",
        "# Basic SVC\n",
        "svc_basic = SVC(random_state=42)\n",
        "svc_basic.fit(X_train_scaled, y_train)\n",
        "svc_pred = svc_basic.predict(X_test_scaled)\n",
        "svc_accuracy = accuracy_score(y_test, svc_pred)\n",
        "\n",
        "print(f\"SVC Basic Accuracy: {svc_accuracy:.4f}\")\n",
        "\n",
        "# SVC with hyperparameter tuning\n",
        "print(\"\\nüîß Tuning SVC hyperparameters...\")\n",
        "svc_param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['rbf', 'linear'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "svc_grid = GridSearchCV(SVC(random_state=42), svc_param_grid, cv=5, scoring='accuracy')\n",
        "svc_grid.fit(X_train_scaled, y_train)\n",
        "svc_best = svc_grid.best_estimator_\n",
        "\n",
        "svc_best_pred = svc_best.predict(X_test_scaled)\n",
        "svc_best_accuracy = accuracy_score(y_test, svc_best_pred)\n",
        "\n",
        "print(f\"SVC Best Parameters: {svc_grid.best_params_}\")\n",
        "print(f\"SVC Best Accuracy: {svc_best_accuracy:.4f}\")\n",
        "\n",
        "# IMPLEMENT KNN\n",
        "print(\"\\n=== KNN IMPLEMENTATION ===\")\n",
        "\n",
        "# Testing different K values\n",
        "k_values = range(1, 21)\n",
        "knn_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5)\n",
        "    knn_scores.append(scores.mean())\n",
        "\n",
        "# Finding best K\n",
        "best_k = k_values[np.argmax(knn_scores)]\n",
        "print(f\"Best K value: {best_k}\")\n",
        "\n",
        "# Training KNN with best K\n",
        "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_best.fit(X_train_scaled, y_train)\n",
        "knn_pred = knn_best.predict(X_test_scaled)\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "\n",
        "print(f\"KNN Best Accuracy: {knn_accuracy:.4f}\")\n",
        "\n",
        "# COMPARE MODELS\n",
        "print(\"\\n=== MODEL COMPARISON ===\")\n",
        "results = {\n",
        "    'SVC Basic': svc_accuracy,\n",
        "    'SVC Tuned': svc_best_accuracy,\n",
        "    'KNN': knn_accuracy\n",
        "}\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "for model, score in results.items():\n",
        "    print(f\"{model}: {score:.4f}\")\n",
        "\n",
        "# Determining winner\n",
        "best_model = max(results, key=results.get)\n",
        "print(f\"\\nüèÜ Best Model: {best_model} with {results[best_model]:.4f} accuracy\")\n",
        "\n",
        "# DETAILED EVALUATION\n",
        "print(f\"\\n=== DETAILED EVALUATION FOR {best_model} ===\")\n",
        "\n",
        "if best_model == 'SVC Tuned':\n",
        "    final_pred = svc_best_pred\n",
        "    final_model = svc_best\n",
        "elif best_model == 'KNN':\n",
        "    final_pred = knn_pred\n",
        "    final_model = knn_best\n",
        "else:\n",
        "    final_pred = svc_pred\n",
        "    final_model = svc_basic\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, final_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, final_pred))"
      ]
    }
  ]
}